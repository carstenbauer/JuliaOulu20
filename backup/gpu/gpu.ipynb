{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computing on GPUs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPU (local)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, let's check if there is a GPU available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using CUDAdrv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CuDevice(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A, B = rand(1000,1000), rand(1000,1000);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's move these arrays to the GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using CuArrays\n",
    "@assert CuArrays.functional() # if this fails your GPU isn't recognized correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Agpu, Bgpu = CuArray(A), CuArray(B);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "typeof(Agpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How much faster is a simple matmul on the GPU? Let's find out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using BenchmarkTools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "println(\"A*B (cpu)\")\n",
    "@btime $A * $B;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "println(\"A*B (gpu)\")\n",
    "@btime $Agpu * $Bgpu;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's at least 3 orders of magnitude faster!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Free GPU memory\n",
    "Agpu, Bgpu = nothing, nothing\n",
    "GC.gc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the result of the multiplication lives on the GPU as well and needs to be pulled back to main memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Agpu, Bgpu = CuArray(A), CuArray(B);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cgpu = Agpu * Bgpu;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "typeof(Cgpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = Matrix(Cgpu); # move to cpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How long does it take to move the `CuArray` back to main memory?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@btime Matrix($Cgpu);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Free GPU memory\n",
    "Agpu, Bgpu, Cgpu = nothing, nothing, nothing\n",
    "GC.gc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Flux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Chain(\n",
    "    Dense(1000, 100),\n",
    "    Dense(100, 10),\n",
    "    Dense(10, 5),\n",
    "    Dense(5, 2),\n",
    "    softmax # normalize output neurons\n",
    "    )\n",
    "\n",
    "data = rand(1000, 1000); # fake data\n",
    "labels = fill(0.5, 2, 1000); # fake data\n",
    "\n",
    "loss(x, y) = sum(Flux.mse(m(x), y)) # mean squared error\n",
    "opt = Descent(0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@time Flux.train!(loss, Flux.params(m), [(data,labels)], opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's train the network on the GPU instead! It's as simple as `|> gpu`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# move the model to the gpu\n",
    "m = Chain(\n",
    "    Dense(1000, 100),\n",
    "    Dense(100, 10),\n",
    "    Dense(10, 5),\n",
    "    Dense(5, 2),\n",
    "    softmax\n",
    "    ) |> gpu\n",
    "\n",
    "# move data to the gpu\n",
    "data = rand(1000, 1000) |> gpu;\n",
    "labels = fill(0.5, 2, 1000) |> gpu;\n",
    "\n",
    "loss(x, y) = sum(Flux.mse(m(x), y))\n",
    "opt = Descent(0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "typeof(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@time Flux.train!(loss, Flux.params(m), [(data,labels)], opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training is about **two orders of magnitude faster** on the GPU in this case!\n",
    "\n",
    "Now that our model is trained, let's feed it some data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m(rand(1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oops. Since our model lives on the GPU we can't feed it with data living in main memory. We must move our model back to the CPU first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_cpu = m |> cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "typeof(m_cpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_cpu(rand(1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPU (remote)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start a worker on a gpu node of a supercomputer cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Distributed\n",
    "addprocs([(\"cbauer17@gpu2\", 1)]; exename=`/projects/ag-trebst/bauer/bin/julia-1.3.1/bin/julia`, exeflags=`--project=/projects/ag-trebst/bauer/JuliaOulu20/backup/gpu`, dir=\"/projects/ag-trebst/bauer/JuliaOulu20/backup/gpu\", tunnel=true)\n",
    "@fetch gethostname()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = (exename=`nice -19 /home/bauer/bin/julia-1.3.1/bin/julia --project=/home/bauer/JuliaOulu20`, dir=\"/home/bauer\")\n",
    "addprocs([(\"l94\", :auto)]; params...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Distributed\n",
    "addprocs([(\"cbauer17@gpu2\", 1)]; exename=`/projects/ag-trebst/bauer/bin/julia-1.3.1/bin/julia`, dir=`/projects/ag-trebst/bauer`, tunnel=true)\n",
    "@fetch gethostname()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the GPU name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@fetch @eval using CUDAdrv\n",
    "@fetch CUDAdrv.name(CuDevice(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@fetch @eval using CuArrays, BenchmarkTools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@fetch begin\n",
    "    A, B = rand(1000,1000), rand(1000,1000);\n",
    "    Agpu, Bgpu = CuArray(A), CuArray(B);\n",
    "    \n",
    "    println(\"Move array CPU -> GPU\")\n",
    "    @btime CuArray($A);\n",
    "    \n",
    "    println(\"A*B (cpu)\")\n",
    "    @btime $A * $B;\n",
    "\n",
    "    println(\"A*B (gpu)\")\n",
    "    @btime $Agpu * $Bgpu;\n",
    "    \n",
    "    \n",
    "    println(\"Move array GPU -> CPU\")\n",
    "    Cgpu = Agpu * Bgpu\n",
    "    @btime Array($Cgpu);\n",
    "    \n",
    "    nothing\n",
    "end"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Julia 1.3.1",
   "language": "julia",
   "name": "julia-1.3"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.3.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
